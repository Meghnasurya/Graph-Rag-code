# Standard library imports
import os
import zipfile
import tempfile
import uuid
import ast
import time
import re
import json
import base64
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from functools import wraps
from threading import Thread

# Third-party imports
import networkx as nx
import jwt
import requests
from requests.auth import HTTPBasicAuth
from dotenv import load_dotenv
from flask import Flask, request, jsonify, render_template, session, redirect, url_for, flash
from pydantic import BaseModel, Field
from werkzeug.security import generate_password_hash, check_password_hash

# Google AI and embeddings
import google.generativeai as genai

# Database imports
from neo4j import GraphDatabase
from qdrant_client import QdrantClient
from qdrant_client.http.models import VectorParams, Distance, PointStruct

# Document processing
from docx import Document

# API integrations
from github import Github
from atlassian import Jira
# Load environment variablesload_dotenv()
# Configurationclass Config:    SECRET_KEY = os.getenv("SECRET_KEY", "your-secret-key-here") # [7]    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") # [8]    NEO4J_URI = os.getenv("NEO4J_URI") # [8]    NEO4J_USER = os.getenv("NEO4J_USER") # [8]    NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD") # [8]    QDRANT_URL = os.getenv("QDRANT_URL") # [8]    QDRANT_API_KEY = os.getenv("QDRANT_API_KEY") # [8]    # GitHub OAuth    GITHUB_CLIENT_ID = os.getenv("GITHUB_CLIENT_ID") # [8]    GITHUB_CLIENT_SECRET = os.getenv("GITHUB_CLIENT_SECRET") # [8]    GITHUB_REDIRECT_URI = os.getenv("GITHUB_REDIRECT_URI", "http://localhost:5003/auth/github/callback") # [8]    # Jira OAuth    JIRA_CLIENT_ID = os.getenv("JIRA_CLIENT_ID") # [8]    JIRA_CLIENT_SECRET = os.getenv("JIRA_CLIENT_SECRET") # [9]    JIRA_REDIRECT_URI = os.getenv("JIRA_REDIRECT_URI", "http://localhost:5003/auth/jira/callback") # [9]
# Configure Geminigenai.configure(api_key=Config.GEMINI_API_KEY) # [9]gemini = genai.GenerativeModel("models/gemini-1.5-flash") # [9]
# Qdrant client setupqdrant = QdrantClient(url=Config.QDRANT_URL, api_key=Config.QDRANT_API_KEY) # [9]
# Configure collectionsDOCS_COLLECTION = "documentation_embeddings" # [9]TESTS_COLLECTION = "test_embeddings" # [9]
# Ensure Qdrant collections existfor collection_name in [DOCS_COLLECTION, TESTS_COLLECTION]: # [10]    try:        collections = [c.name for c in qdrant.get_collections().collections] # [10]        if collection_name not in collections: # [10]            qdrant.create_collection( # [10]                collection_name=collection_name, # [10]                vectors_config=VectorParams(size=768, distance=Distance.COSINE), # [10]            )    except Exception as e:        print(f"[Qdrant] Error checking/creating collection {collection_name}: {e}") # [10]
# Data modelsclass TestGenInput(BaseModel): # [10]    requirement: str = Field(...) # [11]    documentation: str = Field(...) # [11]
class TestOutput(BaseModel): # [11]    test_cases: List[str] # [11]    test_scripts: List[str] # [11]
class UserSession(BaseModel): # [11]    user_id: str # [11]    github_token: Optional[str] = None # [11]    jira_token: Optional[str] = None # [11]    jira_url: Optional[str] = None # [11]    selected_github_repo: Optional[str] = None # [11]    selected_jira_project: Optional[str] = None # [11]
# Authentication decoratordef login_required(f): # [11]    @wraps(f) # [11]    def decorated_function(*args, **kwargs): # [11]        if 'user_id' not in session: # [12]            return redirect(url_for('login')) # [12]        return f(*args, **kwargs) # [12]    return decorated_function # [12]
class GitHubService: # [12]    def __init__(self, token: str): # [12]        self.github = Github(token) # [12]        self.token = token # [12]
    def get_user_repos(self) -> List[Dict]: # [12]        """Get user's repositories""" # [12]        try:            repos = [] # [12]            for repo in self.github.get_user().get_repos(): # [12]                repos.append({ # [12]                    'name': repo.name, # [13]                    'full_name': repo.full_name, # [13]                    'description': repo.description, # [13]                    'private': repo.private # [13]                })            return repos # [13]        except Exception as e:            print(f"Error fetching repos: {e}") # [13]            return [] # [13]
    def get_repo_contents(self, repo_name: str, path: str = "") -> Dict[str, Any]: # [13]        """Get repository contents for documentation and tests""" # [13]        try:            repo = self.github.get_repo(repo_name) # [13]            contents = { # [13]                'docs': {}, # [13]                'tests': {}, # [13]                'code': {} # [13]            }
            def process_contents(items, current_path=""): # [13]                for item in items: # [14]                    if item.type == "file": # [14]                        try:                            if item.name.endswith(('.py', '.js', '.java', '.cpp', '.c')): # [14]                                content = base64.b64decode(item.content).decode('utf-8') # [14]                                if 'test' in item.name.lower() or 'spec' in item.name.lower(): # [14]                                    contents['tests'][item.path] = content # [14]                                else:                                    contents['code'][item.path] = content # [14]                            elif item.name.endswith(('.md', '.txt', '.rst', '.doc')): # [14]                                content = base64.b64decode(item.content).decode('utf-8') # [14]                                contents['docs'][item.path] = content # [14]                        except Exception as e:                            print(f"Error processing file {item.path}: {e}") # [14]                    elif item.type == "dir" and not item.name.startswith('.'): # [14]                        # Recursively process subdirectories                        try:                            sub_contents = repo.get_contents(item.path) # [14]                            process_contents(sub_contents, item.path) # [14]                        except Exception as e:                            print(f"Error processing directory {item.path}: {e}") # [14]
            root_contents = repo.get_contents(path) # [15]            process_contents(root_contents) # [15]            return contents # [15]        except Exception as e:            print(f"Error fetching repo contents: {e}") # [15]            return {'docs': {}, 'tests': {}, 'code': {}} # [15]
class JiraService: # [15]    def __init__(self, url: str, token: str): # [15]        self.jira = Jira(url=url, token=token) # [15]        self.url = url # [15]        self.token = token # [15]
    def get_projects(self) -> List[Dict]: # [15]        """Get user's Jira projects""" # [15]        try:            projects = self.jira.projects() # [15]            return [{'key': p['key'], 'name': p['name']} for p in projects] # [15]        except Exception as e:            print(f"Error fetching Jira projects: {e}") # [4]            return [] # [4]
    def get_test_cases(self, project_key: str) -> List[Dict]: # [4]        """Get test cases from Jira project""" # [4]        try:            # Search for test-related issues            jql = f'project = {project_key} AND (issueType = "Test" OR labels = "test" OR summary ~ "test")' # [4]            issues = self.jira.jql(jql) # [4]            test_cases = [] # [4]            for issue in issues.get('issues', []): # [4]                test_cases.append({ # [4]                    'key': issue['key'], # [16]                    'summary': issue['fields']['summary'], # [16]                    'description': issue['fields'].get('description', ''), # [16]                    'status': issue['fields']['status']['name'] # [16]                })            return test_cases # [16]        except Exception as e:            print(f"Error fetching test cases: {e}") # [16]            return [] # [16]
    # New method to create or update test cases in Jira    def create_or_update_test_case(self, project_key: str, test_data: Dict):        """        Creates a new Jira issue as a test case, or updates an existing one if a match is found.        The matching is based on the suggested file_name from the test generation        matching the Jira issue summary.        """        try:            # Use file_name for summary and content for description            summary = test_data.get('file_name', 'Generated Test Case').replace('.py', '') # Clean up filename for summary            test_code_content = test_data.get('test_code', '')            test_cases_list = test_data.get('test_cases', [])
            # Format test cases for description using Jira Wiki Markup            formatted_test_cases = ""            if test_cases_list:                formatted_test_cases = "\n*h2. Detailed Test Cases:*\n"                for tc in test_cases_list:                    formatted_test_cases += f"{{panel:title={tc.get('name', 'Unnamed Test Case')}|borderStyle=solid|borderColor=#ccc|titleBGColor=#eee|bgColor=#fafafa}}\n"                    formatted_test_cases += f"{{color:grey}}Description:{{color}} {tc.get('description', 'No description.')}\n"                    if tc.get('steps'):                        formatted_test_cases += f"{{color:grey}}Steps:{{color}}\n"                        for i, step in enumerate(tc['steps']):                            formatted_test_cases += f"  - {step}\n"                    if tc.get('expected_result'):                        formatted_test_cases += f"{{color:grey}}Expected Result:{{color}} {tc.get('expected_result', 'No expected result.')}\n"                    formatted_test_cases += "*{{panel}}\n\n"
            description = f"{{code:python}}\n{test_code_content}\n{{code}}{formatted_test_cases}"
            # Attempt to find an existing test case by matching the summary            # Note: This is a simple heuristic. A more robust solution for updates            # might involve a custom Jira field for a unique ID or more complex JQL.            jql_query = f'project = "{project_key}" AND summary ~ "{summary}" AND issueType = "Test"'            existing_issues = self.jira.jql(jql_query).get('issues', [])
            if existing_issues:                # Assuming the first match is the one to update                issue_key = existing_issues['key']                self.jira.issue_update(                    issue_key,                    fields={                        'summary': summary,                        'description': description                    }                )                print(f"Updated Jira test case {issue_key} in project {project_key}")                return issue_key            else:                # Create a new issue if no existing match is found                new_issue = self.jira.create_issue(                    fields={                        'project': {'key': project_key},                        'summary': summary,                        'description': description,                        'issuetype': {'name': 'Test'} # Using 'Test' as the issue type, consistent with `get_test_cases` [4]                    }                )                print(f"Created new Jira test case {new_issue.key} in project {project_key}")                return new_issue.key        except Exception as e:            print(f"Error creating/updating Jira test case: {e}")            return None
class EnhancedGraphRAG: # [16]    def __init__(self): # [16]        self.driver = GraphDatabase.driver(Config.NEO4J_URI, auth=(Config.NEO4J_USER, Config.NEO4J_PASSWORD)) # [16]
    def close(self): # [16]        if self.driver: # [16]            self.driver.close() # [16]
    def verify_connection(self): # [16]        try:            with self.driver.session() as session: # [17]                result = session.run("RETURN 1") # [17]                return result.single() == 1 # [17]        except Exception as e:            print(f"Neo4j connection failed: {e}") # [17]            return False # [17]
    def update_knowledge(self, data: Dict[str, Any], source: str): # [17]        """Update knowledge without clearing existing data""" # [17]        if not self.verify_connection(): # [17]            print("Neo4j connection failed, skipping graph operations") # [17]            return # [17]        try:            with self.driver.session() as session: # [17]                # Add source tracking                session.run( # [17]                    "MERGE (s:Source {name: $source, updated: datetime()})", # [18]                    {"source": source} # [18]                )                # Process documentation                if 'docs' in data: # [18]                    for file_path, content in data['docs'].items(): # [18]                        chunks = self.chunk_text(content) # [18]                        for chunk in chunks: # [18]                            session.run(""" # [18]                                MERGE (s:Source {name: $source})                                MERGE (d:Document {path: $path})                                MERGE (c:Content {text: $chunk})                                MERGE (s)-[:CONTAINS]->(d)                                MERGE (d)-[:HAS_CONTENT]->(c)                                """, {"source": source, "path": file_path, "chunk": chunk})                # Process test cases                if 'tests' in data: # [18]                    for file_path, content in data['tests'].items(): # [19]                        functions = self.extract_test_functions(content) # [19]                        for func_name, func_body in functions: # [19]                            session.run(""" # [19]                                MERGE (s:Source {name: $source})                                MERGE (t:TestFile {path: $path})                                MERGE (f:TestFunction {name: $func_name, body: $func_body})                                MERGE (s)-[:CONTAINS]->(t)                                MERGE (t)-[:HAS_TEST]->(f)                                """, {"source": source, "path": file_path, "func_name": func_name, "func_body": func_body})                # Process code                if 'code' in data: # [19]                    for file_path, content in data['code'].items(): # [20]                        functions = self.extract_functions(content) # [20]                        for func_name, func_doc in functions: # [20]                            session.run(""" # [20]                                MERGE (s:Source {name: $source})                                MERGE (cf:CodeFile {path: $path})                                MERGE (f:Function {name: $func_name, documentation: $func_doc})                                MERGE (s)-[:CONTAINS]->(cf)                                MERGE (cf)-[:HAS_FUNCTION]->(f)                                """, {"source": source, "path": file_path, "func_name": func_name, "func_doc": func_doc})                print(f"Successfully updated knowledge graph with data from {source}") # [20]        except Exception as e:            print(f"Error updating knowledge graph: {e}") # [20]
    def search_related_content(self, query: str, limit: int = 10) -> List[Dict]: # [20]        """Search for related content in the knowledge graph""" # [21]        try:            with self.driver.session() as session: # [21]                result = session.run(""" # [21]                    MATCH (n)                    WHERE n.name CONTAINS $query OR n.text CONTAINS $query OR n.documentation CONTAINS $query                    RETURN n, labels(n) as labels                    LIMIT $limit                    """, {"query": query.lower(), "limit": limit})                return [{"node": record["n"], "labels": record["labels"]} for record in result] # [21]        except Exception as e:            print(f"Error searching graph: {e}") # [21]            return [] # [21]
    def chunk_text(self, text: str, max_chars: int = 400) -> List[str]: # [21]        """Chunk text for storage""" # [22]        if not text or len(text.strip()) < 20: # [22]            return [] # [22]        text = re.sub(r'\s+', ' ', text.strip()) # [22]        chunks = [] # [22]        # Split by paragraphs        paragraphs = text.split('\n\n') # [22]        current_chunk = "" # [22]        for paragraph in paragraphs: # [22]            if len(current_chunk) + len(paragraph) <= max_chars: # [22]                current_chunk += paragraph + "\n" # [22]            else:                if current_chunk: # [22]                    chunks.append(current_chunk.strip()) # [22]                current_chunk = paragraph + "\n" # [23]        if current_chunk: # [23]            chunks.append(current_chunk.strip()) # [23]        return [chunk for chunk in chunks if len(chunk.strip()) >= 20] # [23]
    def extract_test_functions(self, code: str) -> List[tuple]: # [23]        """Extract test functions from code""" # [23]        functions = [] # [23]        try:            tree = ast.parse(code) # [23]            for node in ast.walk(tree): # [23]                if isinstance(node, ast.FunctionDef) and node.name.startswith('test_'): # [23]                    func_body = ast.get_source_segment(code, node) or "" # [23]                    functions.append((node.name, func_body)) # [23]        except Exception as e:            print(f"Error parsing test code: {e}") # [23]        return functions # [23]
    def extract_functions(self, code: str) -> List[tuple]: # [23]        """Extract functions from code""" # [24]        functions = [] # [24]        try:            tree = ast.parse(code) # [24]            for node in ast.walk(tree): # [24]                if isinstance(node, ast.FunctionDef): # [24]                    docstring = ast.get_docstring(node) or "" # [24]                    functions.append((node.name, docstring)) # [24]        except Exception as e:            print(f"Error parsing code: {e}") # [24]        return functions # [24]
class EnhancedEmbeddingRAG: # [24]    def __init__(self): # [24]        self.client = qdrant # [24]
    def update_embeddings(self, data: Dict[str, Any], source: str, collection_name: str): # [25]        """Update embeddings without clearing existing data""" # [25]        try:            chunks = [] # [25]            metadata_list = [] # [25]            # Process different types of content            if 'docs' in data: # [25]                for file_path, content in data['docs'].items(): # [25]                    text_chunks = self.chunk_text(content) # [25]                    chunks.extend(text_chunks) # [25]                    metadata_list.extend([{ # [25]                        'source': source, # [25]                        'type': 'documentation', # [25]                        'file_path': file_path, # [26]                        'text': chunk # [26]                    } for chunk in text_chunks])            if 'tests' in data: # [26]                for file_path, content in data['tests'].items(): # [26]                    test_chunks = self.chunk_text(content) # [26]                    chunks.extend(test_chunks) # [26]                    metadata_list.extend([{ # [26]                        'source': source, # [26]                        'type': 'test', # [26]                        'file_path': file_path, # [26]                        'text': chunk # [26]                    } for chunk in test_chunks])            if 'code' in data: # [26]                for file_path, content in data['code'].items(): # [26]                    code_chunks = self.chunk_text(content) # [26]                    chunks.extend(code_chunks) # [26]                    metadata_list.extend([{ # [26]                        'source': source, # [26]                        'type': 'code', # [26]                        'file_path': file_path, # [26]                        'text': chunk # [26]                    } for chunk in code_chunks])            # Store embeddings            return self.embed_and_store(chunks, metadata_list, collection_name) # [26]        except Exception as e:            print(f"Error updating embeddings: {e}") # [26]            return 0 # [27]
    def embed_and_store(self, chunks: List[str], metadata_list: List[Dict], collection_name: str) -> int: # [27]        """Store embeddings with metadata""" # [27]        if not chunks: # [27]            return 0 # [27]        points = [] # [27]        batch_size = 25 # [27]        for i in range(0, len(chunks), batch_size): # [27]            batch_chunks = chunks[i:i+batch_size] # [27]            batch_metadata = metadata_list[i:i+batch_size] # [27]            batch_points = [] # [27]            for chunk, metadata in zip(batch_chunks, batch_metadata): # [27]                try:                    result = genai.embed_content( # [27]                        model="models/text-embedding-004", # [27]                        content=chunk[:1500], # [27]                        task_type="retrieval_document" # [28]                    )                    embedding = result['embedding'] # [28]                    batch_points.append( # [28]                        PointStruct( # [28]                            id=str(uuid.uuid4()), # [28]                            vector=embedding, # [28]                            payload=metadata # [28]                        )                    )                except Exception as e:                    print(f"Error embedding chunk: {e}") # [28]                    continue # [28]            if batch_points: # [28]                try:                    self.client.upsert(collection_name=collection_name, points=batch_points) # [28]                    points.extend(batch_points) # [28]                except Exception as e:                    print(f"Error storing batch: {e}") # [29]            time.sleep(0.1) # Rate limiting # [29]        return len(points) # [29]
    def search(self, query: str, collection_name: str, top_k: int = 10) -> List[Dict]: # [29]        """Search embeddings""" # [29]        try:            result = genai.embed_content( # [29]                model="models/text-embedding-004", # [29]                content=query, # [29]                task_type="retrieval_query" # [29]            )            query_vec = result['embedding'] # [29]            results = self.client.search( # [29]                collection_name=collection_name, # [30]                query_vector=query_vec, # [30]                limit=top_k, # [30]                score_threshold=0.5 # [30]            )            return [hit.payload for hit in results] # [30]        except Exception as e:            print(f"Error searching embeddings: {e}") # [30]            return [] # [30]
    def chunk_text(self, text: str, max_chars: int = 400) -> List[str]: # [30]        """Chunk text for embedding""" # [30]        if not text or len(text.strip()) < 20: # [30]            return [] # [30]        text = re.sub(r'\s+', ' ', text.strip()) # [30]        chunks = [] # [30]        # Split by paragraphs        paragraphs = text.split('\n\n') # [30]        current_chunk = "" # [30]        for paragraph in paragraphs: # [30]            if len(current_chunk) + len(paragraph) <= max_chars: # [30]                current_chunk += paragraph + "\n" # [30]            else:                if current_chunk: # [31]                    chunks.append(current_chunk.strip()) # [31]                current_chunk = paragraph + "\n" # [31]        if current_chunk: # [31]            chunks.append(current_chunk.strip()) # [31]        return [chunk for chunk in chunks if len(chunk.strip()) >= 20] # [31]
class AgenticRAG: # [31]    def __init__(self): # [31]        self.graph_rag = EnhancedGraphRAG() # [31]        self.embedding_rag = EnhancedEmbeddingRAG() # [31]
    def process_query(self, query: str, user_session: UserSession) -> Dict[str, Any]: # [31]        """Process user query with agentic approach""" # [31]        try:            # Step 1: Search existing knowledge            doc_results = self.embedding_rag.search(query, DOCS_COLLECTION, top_k=5) # [31]            test_results = self.embedding_rag.search(query, TESTS_COLLECTION, top_k=5) # [31]            graph_results = self.graph_rag.search_related_content(query, limit=5) # [32]
            # Step 2: Analyze if existing tests cover the requirement            analysis_prompt = f""" # [32]                Analyze this query: "{query}"                Existing documentation: {json.dumps(doc_results[:2], indent=2)}                Existing tests: {json.dumps(test_results[:2], indent=2)}                Determine:                1. Is there existing functionality for this requirement?                2. Are there existing tests that cover this?                3. What new tests need to be created?                4. Should existing tests be updated?                Respond in JSON format:                {{                    "existing_functionality": true/false,                    "existing_tests": true/false,                    "needs_new_tests": true/false,                    "needs_test_updates": true/false,                    "recommendations": ["list of specific actions"]                }}                """            analysis_response = gemini.generate_content(analysis_prompt) # [1]            analysis = json.loads(analysis_response.text) # [1]
            # Step 3: Generate or update tests based on analysis            if analysis.get('needs_new_tests') or analysis.get('needs_test_updates'): # [1]                test_generation_result = self.generate_tests(query, doc_results, test_results, analysis) # [1]
                # Step 4: Update test repository if needed                # **MODIFIED:** Now updates Jira instead of GitHub based on your request.                # GitHub update logic removed as per your instruction.                if user_session.jira_token and user_session.jira_url and user_session.selected_jira_project:                    self.update_jira_tests(user_session, test_generation_result) # New call to Jira update function                else:                    print("Jira credentials or project not selected, skipping Jira test update.")
                return { # [1]                    'analysis': analysis, # [33]                    'generated_tests': test_generation_result, # [33]                    'updated_embeddings': True # [33]                }            else: # [33]                return { # [33]                    'analysis': analysis, # [33]                    'existing_tests': test_results, # [33]                    'message': 'Existing tests already cover this requirement' # [33]                }        except Exception as e:            print(f"Error processing query: {e}") # [33]            return {'error': str(e)} # [33]
    def generate_tests(self, query: str, doc_context: List[Dict], test_context: List[Dict], analysis: Dict) -> Dict: # [33]        """Generate new tests based on context and analysis""" # [34]        try:            generation_prompt = f""" # [34]                Based on this requirement: "{query}"                Context from documentation: {json.dumps(doc_context, indent=2)}                Context from existing tests: {json.dumps(test_context, indent=2)}                Analysis: {json.dumps(analysis, indent=2)}                Generate comprehensive test cases and Python unittest code.                Return JSON format:                {{                    "test_cases": [                        {{                            "name": "test_case_name",                            "description": "detailed description",                            "steps": ["step1", "step2", "step3"],                            "expected_result": "expected outcome"                        }}                    ],                    "test_code": "complete Python unittest code",                    "file_name": "suggested_test_file_name.py"                }}                """            response = gemini.generate_content(generation_prompt) # [2]            return json.loads(response.text) # [2]        except Exception as e:            print(f"Error generating tests: {e}") # [2]            return {'error': str(e)} # [2]
    # **NEW FUNCTION:** This function handles updating or creating tests in Jira.    def update_jira_tests(self, user_session: UserSession, test_result: Dict):        """        Updates Jira test repository with new or updated test cases.        This function uses the JiraService to create or modify Jira issues        that represent the generated test cases.        """        try:            jira_service = JiraService(user_session.jira_url, user_session.jira_token)            project_key = user_session.selected_jira_project            # Call the new method in JiraService to handle the creation/update logic            jira_service.create_or_update_test_case(project_key, test_result)            print(f"Attempted to update/create Jira test case in project: {project_key}")        except Exception as e:            print(f"Error updating Jira test repository: {e}")
    # **REMOVED/DISABLED:** The original update_github_repo function is no longer called    # and is removed to ensure no changes are made to the GitHub repository as requested.    # def update_github_repo(self, user_session: UserSession, test_result: Dict): # [2]    #     """Update GitHub repository with new tests""" # [2]    #     try:    #         github_service = GitHubService(user_session.github_token) # [2]    #         repo = github_service.github.get_repo(user_session.selected_github_repo) # [2]    #    #         file_path = f"tests/{test_result.get('file_name', 'generated_test.py')}" # [3]    #         test_code = test_result.get('test_code', '') # [3]    #    #         try: # [3]    #             # Try to get existing file    #             existing_file = repo.get_contents(file_path) # [3]    #             # Update existing file    #             repo.update_file( # [3]    #                 file_path, # [3]    #                 f"Update tests: {datetime.now().isoformat()}", # [3]    #                 test_code, # [3]    #                 existing_file.sha # [3]    #             )    #         except: # [3]    #             # Create new file    #             repo.create_file( # [35]    #                 file_path, # [35]    #                 f"Add new tests: {datetime.now().isoformat()}", # [35]    #                 test_code # [35]    #             )    #         print(f"Successfully updated GitHub repository: {file_path}") # [35]    #     except Exception as e:    #         print(f"Error updating GitHub repo: {e}") # [35]

# Flask Applicationapp = Flask(__name__) # [35]app.config.from_object(Config) # [35]
# Initialize servicesagentic_rag = AgenticRAG() # [35]
@app.route("/") # [35]def index(): # [35]    if 'user_id' not in session: # [35]        return redirect(url_for('login')) # [35]    return render_template("dashboard.html") # [36]
@app.route("/login") # [36]def login(): # [36]    return render_template("login.html") # [36]
@app.route("/auth/github") # [36]def github_auth(): # [36]    """Redirect to GitHub OAuth""" # [36]    github_auth_url = f"https://github.com/login/oauth/authorize?client_id={Config.GITHUB_CLIENT_ID}&redirect_uri={Config.GITHUB_REDIRECT_URI}&scope=repo" # [36]    return redirect(github_auth_url) # [36]
@app.route("/auth/github/callback") # [36]def github_callback(): # [36]    """Handle GitHub OAuth callback""" # [36]    code = request.args.get('code') # [36]    if not code: # [36]        flash('GitHub authentication failed') # [36]        return redirect(url_for('login')) # [36]    # Exchange code for token    token_response = requests.post('https://github.com/login/oauth/access_token', { # [36]        'client_id': Config.GITHUB_CLIENT_ID, # [37]        'client_secret': Config.GITHUB_CLIENT_SECRET, # [37]        'code': code # [37]    }, headers={'Accept': 'application/json'}) # [37]    token_data = token_response.json() # [37]    access_token = token_data.get('access_token') # [37]    if access_token: # [37]        # Store in session        session['user_id'] = str(uuid.uuid4()) # [37]        session['github_token'] = access_token # [37]        flash('GitHub authentication successful') # [37]        return redirect(url_for('select_repo')) # [37]    else:        flash('Failed to get GitHub access token') # [37]        return redirect(url_for('login')) # [37]
@app.route("/auth/jira") # [38]def jira_auth(): # [38]    """Redirect to Jira OAuth""" # [38]    jira_auth_url = f"https://auth.atlassian.com/authorize?audience=api.atlassian.com&client_id={Config.JIRA_CLIENT_ID}&scope=read:jira-work&redirect_uri={Config.JIRA_REDIRECT_URI}&response_type=code" # [38]    return redirect(jira_auth_url) # [38]
@app.route("/auth/jira/callback") # [38]def jira_callback(): # [38]    """Handle Jira OAuth callback""" # [38]    code = request.args.get('code') # [38]    if not code: # [38]        flash('Jira authentication failed') # [38]        return redirect(url_for('login')) # [38]    # Exchange code for token    token_response = requests.post('https://auth.atlassian.com/oauth/token', { # [38]        'grant_type': 'authorization_code', # [39]        'client_id': Config.JIRA_CLIENT_ID, # [39]        'client_secret': Config.JIRA_CLIENT_SECRET, # [39]        'code': code, # [39]        'redirect_uri': Config.JIRA_REDIRECT_URI # [39]    })    token_data = token_response.json() # [39]    access_token = token_data.get('access_token') # [39]    if access_token: # [39]        session['jira_token'] = access_token # [39]        flash('Jira authentication successful') # [39]        return redirect(url_for('select_project')) # [39]    else:        flash('Failed to get Jira access token') # [39]        return redirect(url_for('login')) # [40]
@app.route("/select-repo") # [40]@login_required # [40]def select_repo(): # [40]    """Select GitHub repository""" # [40]    if 'github_token' not in session: # [40]        return redirect(url_for('github_auth')) # [40]    github_service = GitHubService(session['github_token']) # [40]    repos = github_service.get_user_repos() # [40]    return render_template("select_repo.html", repos=repos) # [40]
@app.route("/select-project") # [40]@login_required # [41]def select_project(): # [41]    """Select Jira project""" # [41]    if 'jira_token' not in session: # [41]        return redirect(url_for('jira_auth')) # [41]    # Get user's Jira sites    sites_response = requests.get( # [41]        'https://api.atlassian.com/oauth/token/accessible-resources', # [41]        headers={'Authorization': f'Bearer {session["jira_token"]}'} # [41]    )    sites = sites_response.json() # [41]    return render_template("select_project.html", sites=sites) # [41]
@app.route("/process-selections", methods=["POST"]) # [41]@login_required # [41]def process_selections(): # [42]    """Process repository and project selections""" # [42]    github_repo = request.form.get('github_repo') # [42]    jira_site = request.form.get('jira_site') # [42]    jira_project = request.form.get('jira_project') # [42]
    if github_repo: # [42]        session['selected_github_repo'] = github_repo # [42]    if jira_site: # [42]        session['jira_url'] = jira_site # [42]    if jira_project: # [42]        session['selected_jira_project'] = jira_project # [42]
    # Start background process to load data    def load_data(): # [42]        user_session = UserSession( # [42]            user_id=session['user_id'], # [42]            github_token=session.get('github_token'), # [5]            jira_token=session.get('jira_token'), # [5]            jira_url=session.get('jira_url'), # [5]            selected_github_repo=session.get('selected_github_repo'), # [5]            selected_jira_project=session.get('selected_jira_project') # [5]        )
        # Load GitHub data        if user_session.github_token and user_session.selected_github_repo: # [5]            github_service = GitHubService(user_session.github_token) # [5]            repo_data = github_service.get_repo_contents(user_session.selected_github_repo) # [5]            # Update graph and embeddings            agentic_rag.graph_rag.update_knowledge(repo_data, f"github:{user_session.selected_github_repo}") # [5]            agentic_rag.embedding_rag.update_embeddings(repo_data, f"github:{user_session.selected_github_repo}", DOCS_COLLECTION) # [5]            agentic_rag.embedding_rag.update_embeddings(repo_data, f"github:{user_session.selected_github_repo}", TESTS_COLLECTION) # [6]
        # Load Jira data        if user_session.jira_token and user_session.jira_url and user_session.selected_jira_project: # [6]            jira_service = JiraService(user_session.jira_url, user_session.jira_token) # [6]            test_cases = jira_service.get_test_cases(user_session.selected_jira_project) # [6]            # Convert test cases to embeddable format            jira_data = { # [6]                'tests': { # [6]                    f"jira:{tc['key']}": f"{tc['summary']}\n{tc['description']}" for tc in test_cases # [6]                }            }            # Update graph and embeddings with Jira data            agentic_rag.graph_rag.update_knowledge(jira_data, f"jira:{user_session.selected_jira_project}") # [6]            agentic_rag.embedding_rag.update_embeddings(jira_data, f"jira:{user_session.selected_jira_project}", TESTS_COLLECTION) # [43]
    # Start background thread    thread = Thread(target=load_data) # [43]    thread.start() # [43]
    flash('Data loading started in background. You can now use the Agentic RAG system.') # [43]    return redirect(url_for('dashboard')) # [43]
@app.route("/dashboard") # [43]@login_required # [43]def dashboard(): # [44]    """Main dashboard with agentic RAG interface""" # [44]    return render_template("dashboard.html") # [44]
@app.route("/query", methods=["POST"]) # [44]@login_required # [44]def process_query(): # [44]    """Process user query through agentic RAG""" # [44]    query = request.form.get('query') # [44]    if not query: # [44]        return jsonify({'error': 'Query is required'}), 400 # [44]
    user_session = UserSession( # [44]        user_id=session['user_id'], # [44]        github_token=session.get('github_token'), # [44]        jira_token=session.get('jira_token'), # [44]        jira_url=session.get('jira_url'), # [44]        selected_github_repo=session.get('selected_github_repo'), # [44]        selected_jira_project=session.get('selected_jira_project') # [45]    )
    # Process query through agentic RAG    result = agentic_rag.process_query(query, user_session) # [45]    return jsonify(result) # [45]
@app.route("/get-projects", methods=["POST"]) # [45]@login_required # [45]def get_projects(): # [45]    """Get projects for a selected Jira site""" # [45]    site_id = request.form.get('site_id') # [45]    site_url = request.form.get('site_url') # [45]    if not site_id or not site_url: # [45]        return jsonify({'error': 'Site ID and URL are required'}), 400 # [45]
    try:        # Get projects from the selected site        projects_response = requests.get( # [45]            f'{site_url}/rest/api/3/project', # [46]            headers={'Authorization': f'Bearer {session["jira_token"]}'} # [46]        )        if projects_response.status_code == 200: # [46]            projects = projects_response.json() # [46]            return jsonify({'projects': projects}) # [46]        else:            return jsonify({'error': 'Failed to fetch projects'}), 500 # [46]    except Exception as e:        return jsonify({'error': str(e)}), 500 # [46]
@app.route("/logout") # [46]def logout(): # [46]    """Logout user""" # [46]    session.clear() # [46]    flash('You have been logged out') # [46]    return redirect(url_for('login')) # [47]
@app.route("/status") # [47]@login_required # [47]def status(): # [47]    """Get system status""" # [47]    return jsonify({ # [47]        'github_connected': 'github_token' in session, # [47]        'jira_connected': 'jira_token' in session, # [47]        'repo_selected': 'selected_github_repo' in session, # [47]        'project_selected': 'selected_jira_project' in session, # [47]        'collections_info': { # [47]            'docs': len(agentic_rag.embedding_rag.client.get_collection(DOCS_COLLECTION).points_count) if agentic_rag.embedding_rag.client.collection_exists(DOCS_COLLECTION) else 0, # [47]            'tests': len(agentic_rag.embedding_rag.client.get_collection(TESTS_COLLECTION).points_count) if agentic_rag.embedding_rag.client.collection_exists(TESTS_COLLECTION) else 0 # [47]        }    })
if __name__ == "__main__":    app.run(debug=True, host="127.0.0.1", port=5004)